These exemplary Consumers can processes live Netflow data as generated by the
bwNetFlow platform. Usually, this is flow data from border interfaces, possible
filtered to a customer-specific level of granularity.

For most examples, you will need an `authdata` file (it's in `.gitignore`)
which needs to look like this:

```
username-groupname
username
password
```

Note that the groupname is enforced to have your username as a prefix for
namespacing, the rest may be descriptive or random. None of the examples make
use of paralellism or use distinc groupnames, so just one example should be run
at a time, or else Kafka will split the flows between the examples, as they are
sharing a group.

Additionally, `anon_demo.py` works as is, without any `authdata`. Your user
should of course have the proper access level for the topic specified inside
the script. It usually is set to `flow-messages-enriched`, which users at a
participant network will need to change to their custom topic.

The local virtualenv needs to contain the packages `confluent-kafka` and `protobuf`.
